{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FlipRobo Web Scraping Assignment-2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Scp\\Desktop\\fliprobo\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "\n",
    "1.first get the webpage https://www.naukri.com/\n",
    "    \n",
    "2.Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "\n",
    "3.Then click the search button.\n",
    "\n",
    "4.Then scrape the data for the first 10 jobs results you get.\n",
    "\n",
    "5.Finally create a dataframe of the scraped data. \n",
    "\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering details in naukri.com “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_field_location=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_field_designation.send_keys(\"Data Analyst\")\n",
    "search_field_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fresher Data Engineer / Data Scientist / Data Analyst Requirements',\n",
       " 'Data Scientist/Data Analyst']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "    \n",
    "job_title[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delhi NCR, Bengaluru, Hyderabad', 'Chennai, Pune, Bengaluru, Hyderabad']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "job_location[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACHYUTAS SOFT PRIVATE LIMITED',\n",
       " 'CAIA-Center For Artificial Intelligence & Advanced Analytics']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-2 Yrs', '0-3 Yrs']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the experience_required \n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "experience_required[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>ACHYUTAS SOFT PRIVATE LIMITED</td>\n",
       "      <td>Delhi NCR, Bengaluru, Hyderabad</td>\n",
       "      <td>Fresher Data Engineer / Data Scientist / Data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>Data Scientist/Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-3 Yrs</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Business Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>(98 Reviews)</td>\n",
       "      <td>Bengaluru(Whitefield)</td>\n",
       "      <td>SAS AML Data Analyst / Trainee &amp; Data Science,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>MagicBase Royal BD Pvt Ltd</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Hiring Data Analysts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Hiring Data Analysts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>(2603 Reviews)</td>\n",
       "      <td>Bengaluru, India</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Study Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3-4 Yrs</td>\n",
       "      <td>(2603 Reviews)</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10-15 Yrs</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Business Data Analyst | Reinsurance Domain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_required                                       company_name  \\\n",
       "0             0-2 Yrs                      ACHYUTAS SOFT PRIVATE LIMITED   \n",
       "1             0-3 Yrs  CAIA-Center For Artificial Intelligence & Adva...   \n",
       "2             2-3 Yrs                                             NetApp   \n",
       "3             0-5 Yrs                                       (98 Reviews)   \n",
       "4             2-5 Yrs                         MagicBase Royal BD Pvt Ltd   \n",
       "5             2-5 Yrs                  Flipkart Internet Private Limited   \n",
       "6             3-5 Yrs                                     (2603 Reviews)   \n",
       "7             4-8 Yrs                  Flipkart Internet Private Limited   \n",
       "8             3-4 Yrs                                     (2603 Reviews)   \n",
       "9           10-15 Yrs            GlaxoSmithKline Pharmaceuticals Limited   \n",
       "\n",
       "                          job_location  \\\n",
       "0      Delhi NCR, Bengaluru, Hyderabad   \n",
       "1  Chennai, Pune, Bengaluru, Hyderabad   \n",
       "2                            Bengaluru   \n",
       "3                Bengaluru(Whitefield)   \n",
       "4                            Bengaluru   \n",
       "5                            Bengaluru   \n",
       "6                     Bengaluru, India   \n",
       "7                            Bengaluru   \n",
       "8                            Bengaluru   \n",
       "9                            Bengaluru   \n",
       "\n",
       "                                           job_title  \n",
       "0  Fresher Data Engineer / Data Scientist / Data ...  \n",
       "1                        Data Scientist/Data Analyst  \n",
       "2                              Business Data Analyst  \n",
       "3  SAS AML Data Analyst / Trainee & Data Science,...  \n",
       "4                               Hiring Data Analysts  \n",
       "5                               Hiring Data Analysts  \n",
       "6                                       Data Analyst  \n",
       "7                                 Study Data Analyst  \n",
       "8                                       Data Analyst  \n",
       "9         Business Data Analyst | Reinsurance Domain  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_title\":job_title[0:10]})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "\n",
    "1.first get the webpage https://www.naukri.com/\n",
    "    \n",
    "2.Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "\n",
    "3.Then click the search button.\n",
    "\n",
    "4.Then scrape the data for the first 10 jobs results you get.\n",
    "\n",
    "5.Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note- 1. All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Scp\\Desktop\\fliprobo\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_field_location=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "search_field_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "full_job_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fresher Data Engineer / Data Scientist / Data Analyst Requirements',\n",
       " 'Data Scientist/Data Analyst']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "    \n",
    "job_title[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACHYUTAS SOFT PRIVATE LIMITED',\n",
       " 'CAIA-Center For Artificial Intelligence & Advanced Analytics']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delhi NCR, Bengaluru, Hyderabad', 'Chennai, Pune, Bengaluru, Hyderabad']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "job_location[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the full job-description, for scraping full job description we have to go in each of the jobs separately\n",
    "urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")]\n",
    "for url in urls[0:10]:\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//section[@class='job-desc']/div[1]\").text\n",
    "        description=raw_description.replace(\"Contact Person\",\"@@@@@\")\n",
    "        description= description.split(\"@@@@@\")\n",
    "        job_description.append(description[0])\n",
    "    except NoSuchElementException :\n",
    "        job_description.append(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fresher Data Engineer / Data Scientist / Data ...</td>\n",
       "      <td>ACHYUTAS SOFT PRIVATE LIMITED</td>\n",
       "      <td>Delhi NCR, Bengaluru, Hyderabad</td>\n",
       "      <td>Roles and Responsibilities\\nAnalytical Skills:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Analyst</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>Dear Candidate\\n\\nSchedule a Telephonic Interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning/Data Mining</td>\n",
       "      <td>Minions Ventures</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Key Responsibilities :\\n\\n- Use analytical rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist - NLP/ Python/ R</td>\n",
       "      <td>AVI Consulting LLP</td>\n",
       "      <td>Bengaluru, Hyderabad</td>\n",
       "      <td>Roles and Responsibilities\\nSkill : NLP,Semant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "      <td>Roles and Responsibilities\\n\\nMust have strong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>(71 Reviews)</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "      <td>Roles and Responsibilities\\n\\nMust have strong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Python/MATLAB/Machine Learnin...</td>\n",
       "      <td>(71 Reviews)</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Roles and Responsibilities\\nData Scientist - D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/Data Mi...</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Roles and Responsibilities\\nRequirements :\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Machine Learning - Remote Wor...</td>\n",
       "      <td>(119 Reviews)</td>\n",
       "      <td>Delhi NCR, Bengaluru, Anywhere in India</td>\n",
       "      <td>Please note that this role will be 'Remote' i....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0  Fresher Data Engineer / Data Scientist / Data ...   \n",
       "1                        Data Scientist/Data Analyst   \n",
       "2      Data Scientist - Machine Learning/Data Mining   \n",
       "3             Senior Data Scientist - NLP/ Python/ R   \n",
       "4  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "5  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "6                  Data Scientist - Machine Learning   \n",
       "7  Data Scientist - Python/MATLAB/Machine Learnin...   \n",
       "8  Lead Data Scientist - Machine Learning/Data Mi...   \n",
       "9  Data Scientist - Machine Learning - Remote Wor...   \n",
       "\n",
       "                                        company_name  \\\n",
       "0                      ACHYUTAS SOFT PRIVATE LIMITED   \n",
       "1  CAIA-Center For Artificial Intelligence & Adva...   \n",
       "2                                   Minions Ventures   \n",
       "3                                 AVI Consulting LLP   \n",
       "4                                           CES Ltd.   \n",
       "5                                       (71 Reviews)   \n",
       "6                                           CES Ltd.   \n",
       "7                                       (71 Reviews)   \n",
       "8                  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "9                                      (119 Reviews)   \n",
       "\n",
       "                                        job_location  \\\n",
       "0                    Delhi NCR, Bengaluru, Hyderabad   \n",
       "1                Chennai, Pune, Bengaluru, Hyderabad   \n",
       "2                                          Bengaluru   \n",
       "3                               Bengaluru, Hyderabad   \n",
       "4  Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...   \n",
       "5  Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...   \n",
       "6                                          Bengaluru   \n",
       "7                                          Bengaluru   \n",
       "8                                          Bengaluru   \n",
       "9            Delhi NCR, Bengaluru, Anywhere in India   \n",
       "\n",
       "                                     job_description  \n",
       "0  Roles and Responsibilities\\nAnalytical Skills:...  \n",
       "1  Dear Candidate\\n\\nSchedule a Telephonic Interv...  \n",
       "2  Key Responsibilities :\\n\\n- Use analytical rig...  \n",
       "3  Roles and Responsibilities\\nSkill : NLP,Semant...  \n",
       "4  Roles and Responsibilities\\n\\nMust have strong...  \n",
       "5  Roles and Responsibilities\\n\\nMust have strong...  \n",
       "6                                                ---  \n",
       "7  Roles and Responsibilities\\nData Scientist - D...  \n",
       "8  Roles and Responsibilities\\nRequirements :\\n\\n...  \n",
       "9  Please note that this role will be 'Remote' i....  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"job_title\":job_title[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_description\":job_description[0:10]})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below: You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company_name, experience_required. The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs The task will be done as shown in the below steps:\n",
    "\n",
    "1.first get the webpage https://www.naukri.com/\n",
    "    \n",
    "2.Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "\n",
    "3.Then click the search button.\n",
    "\n",
    "4.Then apply the location filter and salary filter by checking the respective boxes\n",
    "\n",
    "5.Then scrape the data for the first 10 jobs results you get.\n",
    "\n",
    "6.Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Scp\\Desktop\\fliprobo\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering “Data Scientist” in “Skill,Designations,Companies” field \n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "\n",
    "search_field_designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the location check box\n",
    "loc=driver.find_element_by_xpath(\"//span[@title='Delhi/NCR']\")\n",
    "\n",
    "# clicking the check box\n",
    "loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the salary check box\n",
    "loc=driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs']\")\n",
    "\n",
    "# clicking the check box\n",
    "loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fresher Data Engineer / Data Scientist / Data Analyst Requirements',\n",
       " 'GCP Skilled Analytics Resources (Data engineer / Data scientists)']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "    \n",
    "job_title[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delhi NCR, Bengaluru, Hyderabad', 'Pune, Bengaluru, Gurgaon']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "job_location[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-2 Yrs', '3-8 Yrs']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:2]\n",
    "\n",
    " #scraping the experience_required \n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "experience_required[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>ACHYUTAS SOFT PRIVATE LIMITED</td>\n",
       "      <td>Delhi NCR, Bengaluru, Hyderabad</td>\n",
       "      <td>Fresher Data Engineer / Data Scientist / Data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Aerial Telecom Solutions Pvt. Ltd.</td>\n",
       "      <td>Pune, Bengaluru, Gurgaon</td>\n",
       "      <td>GCP Skilled Analytics Resources (Data engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>(193 Reviews)</td>\n",
       "      <td>Pune, Bengaluru, Gurgaon</td>\n",
       "      <td>GCP Skilled Analytics Resources (Data engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Aerial Telecom Solutions Pvt. Ltd.</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Data Scientist - Python/Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>(193 Reviews)</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Jubna</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9-14 Yrs</td>\n",
       "      <td>PureSoftware Pvt Ltd.</td>\n",
       "      <td>Delhi NCR, Noida(Sector-142 Noida)</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9-14 Yrs</td>\n",
       "      <td>(87 Reviews)</td>\n",
       "      <td>Delhi NCR(Sector-142 Noida), Noida</td>\n",
       "      <td>Excellent opportunity For Lead Data Scientist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9-14 Yrs</td>\n",
       "      <td>World Wide Technology</td>\n",
       "      <td>Delhi NCR, Noida(Sector-142 Noida)</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9-14 Yrs</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LTD</td>\n",
       "      <td>Delhi NCR(Sector-142 Noida), Noida</td>\n",
       "      <td>Excellent opportunity For Lead Data Scientist ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_required                        company_name  \\\n",
       "0             0-2 Yrs       ACHYUTAS SOFT PRIVATE LIMITED   \n",
       "1             3-8 Yrs  Aerial Telecom Solutions Pvt. Ltd.   \n",
       "2             3-8 Yrs                       (193 Reviews)   \n",
       "3             5-8 Yrs  Aerial Telecom Solutions Pvt. Ltd.   \n",
       "4             5-9 Yrs                       (193 Reviews)   \n",
       "5             3-8 Yrs                               Jubna   \n",
       "6            9-14 Yrs               PureSoftware Pvt Ltd.   \n",
       "7            9-14 Yrs                        (87 Reviews)   \n",
       "8            9-14 Yrs               World Wide Technology   \n",
       "9            9-14 Yrs   NEC CORPORATION INDIA PRIVATE LTD   \n",
       "\n",
       "                         job_location  \\\n",
       "0     Delhi NCR, Bengaluru, Hyderabad   \n",
       "1            Pune, Bengaluru, Gurgaon   \n",
       "2            Pune, Bengaluru, Gurgaon   \n",
       "3                               Noida   \n",
       "4                             Gurgaon   \n",
       "5                             Gurgaon   \n",
       "6  Delhi NCR, Noida(Sector-142 Noida)   \n",
       "7  Delhi NCR(Sector-142 Noida), Noida   \n",
       "8  Delhi NCR, Noida(Sector-142 Noida)   \n",
       "9  Delhi NCR(Sector-142 Noida), Noida   \n",
       "\n",
       "                                           job_title  \n",
       "0  Fresher Data Engineer / Data Scientist / Data ...  \n",
       "1  GCP Skilled Analytics Resources (Data engineer...  \n",
       "2  GCP Skilled Analytics Resources (Data engineer...  \n",
       "3           Data Scientist - Python/Machine Learning  \n",
       "4                                     Data Scientist  \n",
       "5                                     Data Scientist  \n",
       "6                                Lead Data Scientist  \n",
       "7  Excellent opportunity For Lead Data Scientist ...  \n",
       "8                                Lead Data Scientist  \n",
       "9  Excellent opportunity For Lead Data Scientist ...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_title\":job_title[0:10]})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company. This task will be done in following steps:\n",
    "\n",
    "1.first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "    \n",
    "2.Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "\n",
    "3.Then click the search button. You will land up in the below page:\n",
    "    \n",
    "4.Then scrape the data for the first 10 jobs results you get in the above shown page. WEB SCRAPING ASSIGNMENT-2 .\n",
    "\n",
    "5.Finally create a dataframe of the scraped data. \n",
    "\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Scp\\Desktop\\fliprobo\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.glassdoor.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering “Data Scientist” in “Skill,Designations,Companies” field \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='sc.keyword']\"))).send_keys(\"Data Scientist\")\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='sc.location']\"))).send_keys(\"Noida\")\n",
    "\n",
    "\n",
    "#search_field_designation=driver.find_element_by_xpath(\"//input[@id='sc.keyword']\")\n",
    "#search_field_designation.send_keys(\"Data Scientist\")\n",
    "#search_field_location=driver.find_element_by_xpath(\"//input[@id='sc.location']\")\n",
    "#search_field_location.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH,\"//button[@data-test='search-bar-submit']\"))).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "\n",
    "company_ratings=[]\n",
    "company_name=[]\n",
    "days_ago=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Raytheon Missiles & Defense', 'Humana']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the element where company name is present\n",
    "companies=driver.find_elements_by_xpath(\"//a[@class=' css-10l5u4p e1n63ojh0 jobLink']/span\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.8', '3.9']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the element where ratings of the company  is present\n",
    "ratings=driver.find_elements_by_xpath(\"//span[@class='compactStars ']\")\n",
    "for i in ratings:\n",
    "    if i.text is None :\n",
    "        company_ratings.append(\"--\") \n",
    "    else:\n",
    "        company_ratings.append(i.text)\n",
    "company_ratings[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '6']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the element where  No. of days ago when job was posted is present\n",
    "days=driver.find_elements_by_xpath(\"//div[@data-test='job-age']\")\n",
    "for i in days:\n",
    "    if i.text is None :\n",
    "        days_ago.append(\"--\") \n",
    "    else:\n",
    "        days_ago.append(i.text[0])\n",
    "days_ago[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_ratings</th>\n",
       "      <th>days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raytheon Missiles &amp; Defense</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Humana</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCAN Group</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Virginia Dept of General Services</td>\n",
       "      <td>4.2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AstraZeneca</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Metron, Inc.</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BankUnited</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Plante Moran</td>\n",
       "      <td>4.6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lumos Diagnostics</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Johns Hopkins Applied Physics Laboratory (APL)</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     company_name company_ratings days_ago\n",
       "0                     Raytheon Missiles & Defense             3.8        1\n",
       "1                                          Humana             3.9        6\n",
       "2                                      SCAN Group             2.3        2\n",
       "3               Virginia Dept of General Services             4.2        8\n",
       "4                                     AstraZeneca               3        1\n",
       "5                                    Metron, Inc.             2.9        2\n",
       "6                                      BankUnited             3.9        2\n",
       "7                                    Plante Moran             4.6        8\n",
       "8                               Lumos Diagnostics             2.8        6\n",
       "9  Johns Hopkins Applied Physics Laboratory (APL)             4.1        1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"company_name\":company_name[0:10],\"company_ratings\":company_ratings[0:10],\"days_ago\":days_ago[0:10]\n",
    "                })\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location. You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary. The above task will be, done as shown in the below steps:\n",
    "\n",
    "1.first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "    \n",
    "2.Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "\n",
    "3.Click the search button.\n",
    "\n",
    "4.After that you will land on the below page You have to scrape whole data from this webpage\n",
    "\n",
    "5.Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "\n",
    "6.Store the data in a dataframe.\n",
    "\n",
    "Note that all of the above steps have to be done by coding only and not manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Scp\\Desktop\\fliprobo\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.glassdoor.co.in/Salaries/index.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering “Data Scientist” in “Skill,Designations,Companies” field \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='KeywordSearch']\"))).send_keys(\"Data Scientist\")\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='LocationSearch']\"))).send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH,\"//button[@data-test='search-bar-submit']\"))).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_salaries=[]\n",
    "max_salaries=[]\n",
    "average_salaries=[]\n",
    "company_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹705K', '₹571K']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the element where min salary   is present\n",
    "min_salary=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[1]\")\n",
    "for i in min_salary:\n",
    "    if i.text is None :\n",
    "        min_salaries.append(\"--\") \n",
    "    else:\n",
    "        \n",
    "        min_salaries.append(i.text)\n",
    "min_salaries[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹11,495K', '₹2,200K']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the element where max salary   is present\n",
    "max_salary=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[2]\")\n",
    "for i in max_salary:\n",
    "    if i.text is None :\n",
    "        max_salaries.append(\"--\") \n",
    "    else:\n",
    "        max_salaries.append(i.text)\n",
    "max_salaries[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹11,495K', '₹2,200K']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the element where average salary   is present\n",
    "average_salary=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[2]\")\n",
    "for i in average_salary:\n",
    "    if i.text is None :\n",
    "        average_salaries.append(\"--\") \n",
    "    else:\n",
    "        average_salaries.append(i.text)\n",
    "average_salaries[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delhivery', 'Accenture']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the element where company_name   is present\n",
    "company=driver.find_elements_by_xpath(\"//div[@data-test='job-info']/p[2]\")\n",
    "for i in company:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\")      \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th></th>\n",
       "      <th>days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>4.2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         company_name      days_ago\n",
       "0           Delhivery  3.8        1\n",
       "1           Accenture  3.9        6\n",
       "2                 IBM  2.3        2\n",
       "3  Ericsson-Worldwide  4.2        8\n",
       "4  UnitedHealth Group    3        1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"company_name\":company_name[0:10],\"\":company_ratings[0:10],\"days_ago\":days_ago[0:10]\n",
    "                })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "\n",
    "1.Brand\n",
    "\n",
    "2.Product Description\n",
    "\n",
    "3.Price\n",
    "\n",
    "4.Discount To scrape the data you have to go through following steps:\n",
    "    \n",
    "5.Go to flipkart webpage by url https://www.flipkart.com/\n",
    "    \n",
    "6.Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "\n",
    "7.After that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "\n",
    "8.After scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Scp\\Desktop\\fliprobo\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the search bar\n",
    "search_bar=driver.find_element_by_class_name('_3704LK')\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the button and clicking it toh search for sunglasses\n",
    "button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-cb00208a2a02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mdiscount\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mnxt_button\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//a[@class='_2Xp0TH']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#scraping the list of buttons from the page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnxt_button\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#getting the link from the list for next page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#scrapping the required details\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):#for loop for scrapping 3 page\n",
    "    brands=driver.find_elements_by_class_name('_2B_pmu')#scraping brands name by class name='_2B_pmu'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    desc=driver.find_elements_by_class_name('_2mylT6')#scraping description by class name = '_2mylT6'\n",
    "    for i in desc:\n",
    "        description.append(i.get_attribute('title'))#appending the description in list\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_1vC4OE']\")# scraping the price from the xpath\n",
    "    for i in prices[:40]:\n",
    "        price.append(i.text)\n",
    "    disc=driver.find_elements_by_xpath(\"//div[@class='VGWI6T']\")# scraping the discount from the xpath\n",
    "    for i in disc:\n",
    "        discount.append(i.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_2Xp0TH']\")#scraping the list of buttons from the page\n",
    "    driver.get(nxt_button[page].get_attribute('href'))#getting the link from the list for next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Scp\\Desktop\\fliprobo\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "Title=[]\n",
    "Ratings=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialising driver\n",
    "driver.get(' https://www.amazon.in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the search bar\n",
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")    # Locating searc_bar by id\n",
    "search_bar.clear()                                               # clearing search_bar\n",
    "search_bar.send_keys(\"laptops\")                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//span[@id=\"nav-search-submit-text\"]')       # Locating search_button by xpath\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the core i7 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the core i9 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping Titles\n",
    "titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in titles[:10]:\n",
    "    Title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping Price\n",
    "prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in prices[:10]:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating Ratings\n",
    "urls=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")#collecting urls of all the laptop\n",
    "UR=[]\n",
    "for i in urls[:10]:\n",
    "    UR.append(i.get_attribute('href'))#getting the url of first 10 laptops\n",
    "for url in UR:#loop for every laptop in the list\n",
    "    driver.get(url)\n",
    "    try:                  #exception handling for nosuchelementexception\n",
    "        rate=driver.find_element_by_xpath(\"//span[@id='acrCustomerReviewText']\")#locating the ratingd link\n",
    "        rate.click()                                                      #click the rating link found\n",
    "        rating=driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-base']\")#locating the rating\n",
    "        Ratings.append(rating.text)#appending the ratings in Ratings list\n",
    "        \n",
    "    except NoSuchElementException   as e:\n",
    "        Ratings.append(\"NO rating\")#appending the No rating if no rating is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#checking the length of each list\n",
    "print(len(Title))\n",
    "print(len(price))\n",
    "print(len(Ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title     Price       Ratings\n",
      "0  Asus VivoBook Gaming (2020) Core i7 10th Gen -...    81,990     NO rating\n",
      "1  Asus ROG Strix G15 Core i7 10th Gen - (8 GB/51...    84,990     NO rating\n",
      "2  ASUS TUF Gaming F15 Laptop 15.6\" FHD Intel Cor...    73,990  3.5 out of 5\n",
      "3  Asus VivoBook S14 Core i7 8th Gen - (8 GB/1 TB...    69,990     NO rating\n",
      "4  (Renewed) Dell Inspiron 3567 Laptop Core i3-7t...    29,990     NO rating\n",
      "5  ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...    95,840    5 out of 5\n",
      "6  (Renewed) Lenovo ThinkPad High Performance 12....    34,999  3.4 out of 5\n",
      "7  ASUS ROG G703GI-E5148T 17.3-inch FHD 144Hz/3ms...  4,99,990    4 out of 5\n",
      "8  Lenovo ThinkPad E14 Intel Core i7 10th Gen14-i...    84,990     NO rating\n",
      "9  ASUS ZenBook Flip S OLED, Intel Evo Core i7-11...  1,49,990     NO rating\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Title':Title,\n",
    "                'Price':price,\n",
    "                'Ratings':Ratings})\n",
    "#printing dataframe\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
